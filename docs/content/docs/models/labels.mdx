---
title: Labels
description: What the Tested, Untested, and Known Issues labels mean and observed behaviors for certain models.
---

<Callout type="warning" title="Potential Streaming Issues">
  Streaming may behave inconsistently in models other than **OpenAI**. We're
  aware of the issue and are actively working on a fix. Please proceed with
  caution when using streaming on non-OpenAI models.
</Callout>

Models in tambo carry a **status label**, shown when you select a model from the LLM settings  
(**Dashboard → Project → Settings → LLM Providers**).

### Why Use Labels?

- **Set expectations**: Understand tambo’s confidence level for each model.
- **Guide selection**: Prefer `tested` models for production; approach others with care.
- **Highlight caveats**: `known-issues` labels call out specific behaviors we've observed.

### Label Definitions

| Label          | Meaning                                                            |
| -------------- | ------------------------------------------------------------------ |
| `tested`       | Validated on common tambo tasks. Recommended for most workflows.   |
| `untested`     | Available, but not yet validated. Use it—but test in your context. |
| `known-issues` | Usable, but we’ve observed behaviors worth noting (see below).     |

### Observed Behaviors & Notes

These behaviors were noted during testing on common tambo tasks. The models below are still usable—just keep the caveats in mind.

#### Google

- **Gemini 2.5 Pro / 2.5 Flash / 2.0 Flash / 2.0 Flash Lite**:
  - May occasionally resist rendering as requested. Sometimes it completes the request, but behavior can be inconsistent.
  - Try clarifying instructions (e.g., “Return a bulleted list only”).
  - Outputs may have formatting quirks. Be cautious when structure matters.

#### Anthropic

- **Claude 3.5 Haiku**:
  - May fail to fully render components, even when receiving the correct data.
  - _Example:_ When rendering a graph component, it may leave it in a loading state without streaming the data into props.

#### Mistral

- **Mistral Large 2.1 / Medium 3**:
  - Similar to Gemini, may inconsistently follow rendering instructions.
  - Try clarifying the prompt structure.
  - Formatting idiosyncrasies can occur—validate outputs where structure is important.

<Callout type="info" title="Production Guidance">
  For production-critical formatting, use **Tested** models and validate
  outputs. When using **Untested** or **Known Issues** models, run a small
  prompt suite to check behavior in your specific workload.
</Callout>

### Usage Patterns

- **Prefer `tested`** models for reliability. If using others, test with your use case.
- **Use inline notes** in the picker to spot caveats quickly.

### Integration

You can change providers and models at the project level under **LLM Provider Settings**. tambo will apply your token limits and defaults accordingly.
